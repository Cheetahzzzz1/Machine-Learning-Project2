{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl24ndqiNRXoF2nhZLAdSk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Project 2\n",
        "\n",
        "Ayush Sinha LNU\n",
        "\n",
        "121334060\n",
        "\n",
        "Machine Learning (MSML603)"
      ],
      "metadata": {
        "id": "h8Ls63aeo8yU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixhGEjM22mgr",
        "outputId": "77a1d721-0278-42f3-e808-2c16b62d213b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "\n",
        "# Function to load MNIST data\n",
        "def load_mnist_images(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        # Unpack file header\n",
        "        _, num_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
        "        # Read the image data\n",
        "        data = np.fromfile(f, dtype=np.uint8).reshape(num_images, rows, cols)\n",
        "        return data\n",
        "\n",
        "def load_mnist_labels(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        # Unpack file header\n",
        "        _, num_labels = struct.unpack('>II', f.read(8))\n",
        "        # Read the label data\n",
        "        data = np.fromfile(f, dtype=np.uint8)\n",
        "        return data\n",
        "\n",
        "# Load data\n",
        "train_images = load_mnist_images('/content/train-images.idx3-ubyte')\n",
        "train_labels = load_mnist_labels('/content/train-labels.idx1-ubyte')\n",
        "test_images = load_mnist_images('/content/t10k-images.idx3-ubyte')\n",
        "test_labels = load_mnist_labels('/content/t10k-labels.idx1-ubyte')\n",
        "\n",
        "# Normalize the image data\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "# Flatten labels\n",
        "train_labels = train_labels.flatten()\n",
        "test_labels = test_labels.flatten()\n",
        "\n",
        "# Confirm data shapes\n",
        "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MNIST data has been successfully loaded and preprocessed:-\n",
        "\n",
        "*   Training Images: 60,000 samples of 28x28 pixels.\n",
        "*   Training Labels: 60,000 corresponding labels.\n",
        "\n",
        "*   Testing Images: 10,000 samples of 28x28 pixels.\n",
        "*   Testing Labels: 10,000 corresponding labels.\n",
        "\n",
        "The pixel values have been normalized to the range [0,1].\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zi17lZlzpPy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels_categorical = to_categorical(train_labels, num_classes=10)\n",
        "test_labels_categorical = to_categorical(test_labels, num_classes=10)\n",
        "\n",
        "# Define the feedforward neural network\n",
        "ffnn_model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),  # Flatten the input\n",
        "    Dense(128, activation='relu'),  # First hidden layer\n",
        "    Dropout(0.2),                   # Dropout for regularization\n",
        "    Dense(64, activation='relu'),   # Second hidden layer\n",
        "    Dense(10, activation='softmax') # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "ffnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "ffnn_history = ffnn_model.fit(\n",
        "    train_images, train_labels_categorical,\n",
        "    validation_data=(test_images, test_labels_categorical),\n",
        "    epochs=10, batch_size=64, verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "ffnn_test_loss, ffnn_test_accuracy = ffnn_model.evaluate(test_images, test_labels_categorical, verbose=0)\n",
        "\n",
        "ffnn_test_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRxTcY802_kD",
        "outputId": "c45e854a-b206-4650-b365-f055340c86b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8282 - loss: 0.5730 - val_accuracy: 0.9606 - val_loss: 0.1306\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9543 - loss: 0.1504 - val_accuracy: 0.9694 - val_loss: 0.0991\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.1121 - val_accuracy: 0.9740 - val_loss: 0.0848\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9725 - loss: 0.0915 - val_accuracy: 0.9740 - val_loss: 0.0837\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9765 - loss: 0.0755 - val_accuracy: 0.9750 - val_loss: 0.0784\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0663 - val_accuracy: 0.9766 - val_loss: 0.0759\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0608 - val_accuracy: 0.9754 - val_loss: 0.0785\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0524 - val_accuracy: 0.9778 - val_loss: 0.0745\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.0494 - val_accuracy: 0.9787 - val_loss: 0.0740\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 0.0439 - val_accuracy: 0.9790 - val_loss: 0.0693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9789999723434448"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code implements a Feedforward Neural Networks over 10 epochs for a single run and gives us the accuracy.\n",
        "\n",
        "Here, val_accuracy is the actual Validation/Testing Accuracy which we are concerned with."
      ],
      "metadata": {
        "id": "z7VTpTulp_i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Reload the necessary libraries and preprocess data as the context was reset\n",
        "import numpy as np\n",
        "import struct\n",
        "\n",
        "# Function to load MNIST images\n",
        "def load_mnist_images(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        _, num_images, rows, cols = struct.unpack('>IIII', f.read(16))  # Read header\n",
        "        data = np.fromfile(f, dtype=np.uint8).reshape(num_images, rows, cols)  # Read image data\n",
        "        return data\n",
        "\n",
        "# Function to load MNIST labels\n",
        "def load_mnist_labels(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        _, num_labels = struct.unpack('>II', f.read(8))  # Read header\n",
        "        data = np.fromfile(f, dtype=np.uint8)  # Read label data\n",
        "        return data\n",
        "\n",
        "# Paths to the MNIST dataset files\n",
        "train_images_file = '/content/train-images.idx3-ubyte'\n",
        "train_labels_file = '/content/train-labels.idx1-ubyte'\n",
        "test_images_file = '/content/t10k-images.idx3-ubyte'\n",
        "test_labels_file = '/content/t10k-labels.idx1-ubyte'\n",
        "\n",
        "# Load training and test images, and normalize pixel values to [0, 1]\n",
        "train_images = load_mnist_images(train_images_file).astype('float32') / 255.0\n",
        "test_images = load_mnist_images(test_images_file).astype('float32') / 255.0\n",
        "\n",
        "# Load training and test labels\n",
        "train_labels = load_mnist_labels(train_labels_file).flatten()\n",
        "test_labels = load_mnist_labels(test_labels_file).flatten()\n",
        "\n",
        "# Reshape images to include a channel dimension (for grayscale images: 1 channel)\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels_categorical = to_categorical(train_labels, num_classes=10)\n",
        "test_labels_categorical = to_categorical(test_labels, num_classes=10)\n",
        "\n",
        "# Define the CNN model architecture\n",
        "cnn_model = Sequential([\n",
        "    # First Convolutional Layer\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),  # Max pooling to reduce spatial dimensions\n",
        "    Dropout(0.25),  # Dropout for regularization\n",
        "\n",
        "    # Second Convolutional Layer\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),  # Max pooling to further reduce dimensions\n",
        "    Dropout(0.25),  # Dropout for regularization\n",
        "\n",
        "    # Flatten the feature maps for the fully connected layers\n",
        "    Flatten(),\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    Dense(128, activation='relu'),  # Dense layer with ReLU activation\n",
        "    Dropout(0.5),  # Dropout to prevent overfitting\n",
        "\n",
        "    # Output Layer\n",
        "    Dense(10, activation='softmax')  # Softmax for multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),  # Adam optimizer with default learning rate\n",
        "    loss='categorical_crossentropy',      # Loss function for multi-class classification\n",
        "    metrics=['accuracy']                  # Metric to monitor training and validation accuracy\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "cnn_history = cnn_model.fit(\n",
        "    train_images, train_labels_categorical,        # Training data\n",
        "    validation_data=(test_images, test_labels_categorical),  # Validation data\n",
        "    epochs=10,                                     # Number of epochs\n",
        "    batch_size=64,                                 # Batch size\n",
        "    verbose=1                                      # Display progress during training\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(\n",
        "    test_images, test_labels_categorical, verbose=0\n",
        ")\n",
        "\n",
        "# Print test accuracy\n",
        "cnn_test_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEXPyJYR2_Qm",
        "outputId": "db8cd490-cb1b-4c64-cbc1-484067e2fcbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 61ms/step - accuracy: 0.8147 - loss: 0.5656 - val_accuracy: 0.9820 - val_loss: 0.0562\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - accuracy: 0.9671 - loss: 0.1135 - val_accuracy: 0.9871 - val_loss: 0.0383\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - accuracy: 0.9749 - loss: 0.0820 - val_accuracy: 0.9893 - val_loss: 0.0299\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - accuracy: 0.9796 - loss: 0.0692 - val_accuracy: 0.9894 - val_loss: 0.0292\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 61ms/step - accuracy: 0.9818 - loss: 0.0586 - val_accuracy: 0.9915 - val_loss: 0.0265\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 61ms/step - accuracy: 0.9843 - loss: 0.0533 - val_accuracy: 0.9916 - val_loss: 0.0258\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 61ms/step - accuracy: 0.9856 - loss: 0.0472 - val_accuracy: 0.9928 - val_loss: 0.0231\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 62ms/step - accuracy: 0.9867 - loss: 0.0426 - val_accuracy: 0.9921 - val_loss: 0.0232\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 60ms/step - accuracy: 0.9860 - loss: 0.0438 - val_accuracy: 0.9926 - val_loss: 0.0223\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 60ms/step - accuracy: 0.9877 - loss: 0.0418 - val_accuracy: 0.9918 - val_loss: 0.0251\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9918000102043152"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code implemnts Convolutional Neural Network over 10 epochs for a single run."
      ],
      "metadata": {
        "id": "NnKcXamuqX2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Function to load MNIST data\n",
        "def load_mnist_images(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        _, num_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
        "        data = np.fromfile(f, dtype=np.uint8).reshape(num_images, rows, cols)\n",
        "        return data\n",
        "\n",
        "def load_mnist_labels(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        _, num_labels = struct.unpack('>II', f.read(8))\n",
        "        data = np.fromfile(f, dtype=np.uint8)\n",
        "        return data\n",
        "\n",
        "# Paths to the MNIST dataset files\n",
        "train_images_file = '/content/train-images.idx3-ubyte'\n",
        "train_labels_file = '/content/train-labels.idx1-ubyte'\n",
        "test_images_file = '/content/t10k-images.idx3-ubyte'\n",
        "test_labels_file = '/content/t10k-labels.idx1-ubyte'\n",
        "\n",
        "# Load data\n",
        "train_images = load_mnist_images(train_images_file).astype('float32') / 255.0\n",
        "test_images = load_mnist_images(test_images_file).astype('float32') / 255.0\n",
        "train_labels = load_mnist_labels(train_labels_file).flatten()\n",
        "test_labels = load_mnist_labels(test_labels_file).flatten()\n",
        "\n",
        "# Reshape data\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels_categorical = to_categorical(train_labels, num_classes=10)\n",
        "test_labels_categorical = to_categorical(test_labels, num_classes=10)\n",
        "\n",
        "# Train and evaluate the feedforward model for multiple runs\n",
        "num_runs = 5\n",
        "test_accuracies = []\n",
        "\n",
        "for run in range(num_runs):\n",
        "    # Define the feedforward neural network model\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28, 1)),          # Flatten the input\n",
        "        Dense(256, activation='relu'),            # First hidden layer\n",
        "        BatchNormalization(),                     # Batch normalization\n",
        "        Dropout(0.3),                             # Dropout for regularization\n",
        "        Dense(128, activation='relu'),            # Second hidden layer\n",
        "        BatchNormalization(),                     # Batch normalization\n",
        "        Dropout(0.3),                             # Dropout for regularization\n",
        "        Dense(64, activation='relu'),             # Third hidden layer\n",
        "        BatchNormalization(),                     # Batch normalization\n",
        "        Dropout(0.2),                             # Dropout for regularization\n",
        "        Dense(10, activation='softmax')           # Output layer\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        train_images, train_labels_categorical,\n",
        "        validation_data=(test_images, test_labels_categorical),\n",
        "        epochs=10, batch_size=64, verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    _, test_accuracy = model.evaluate(test_images, test_labels_categorical, verbose=0)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "# Calculate the average testing accuracy\n",
        "average_test_accuracy = np.mean(test_accuracies)\n",
        "\n",
        "# Print the results\n",
        "print(\"Test Accuracies for each run:\", test_accuracies)\n",
        "print(\"Average Test Accuracy:\", average_test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6-utllj4z6f",
        "outputId": "aa8e63b8-c986-4888-fb46-ae44bc29c77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8039 - loss: 0.6452 - val_accuracy: 0.9544 - val_loss: 0.1389\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9382 - loss: 0.2060 - val_accuracy: 0.9669 - val_loss: 0.1071\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9524 - loss: 0.1537 - val_accuracy: 0.9730 - val_loss: 0.0902\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9590 - loss: 0.1349 - val_accuracy: 0.9705 - val_loss: 0.0959\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9626 - loss: 0.1216 - val_accuracy: 0.9769 - val_loss: 0.0730\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9668 - loss: 0.1071 - val_accuracy: 0.9782 - val_loss: 0.0726\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9707 - loss: 0.0949 - val_accuracy: 0.9788 - val_loss: 0.0687\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9714 - loss: 0.0943 - val_accuracy: 0.9788 - val_loss: 0.0718\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9736 - loss: 0.0862 - val_accuracy: 0.9807 - val_loss: 0.0632\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9751 - loss: 0.0761 - val_accuracy: 0.9810 - val_loss: 0.0652\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.7998 - loss: 0.6461 - val_accuracy: 0.9563 - val_loss: 0.1348\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9392 - loss: 0.2004 - val_accuracy: 0.9638 - val_loss: 0.1138\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9523 - loss: 0.1577 - val_accuracy: 0.9688 - val_loss: 0.0998\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9608 - loss: 0.1316 - val_accuracy: 0.9745 - val_loss: 0.0817\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9643 - loss: 0.1169 - val_accuracy: 0.9767 - val_loss: 0.0749\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9666 - loss: 0.1087 - val_accuracy: 0.9770 - val_loss: 0.0729\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9701 - loss: 0.0983 - val_accuracy: 0.9780 - val_loss: 0.0674\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9721 - loss: 0.0905 - val_accuracy: 0.9788 - val_loss: 0.0677\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9742 - loss: 0.0848 - val_accuracy: 0.9796 - val_loss: 0.0648\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9754 - loss: 0.0802 - val_accuracy: 0.9811 - val_loss: 0.0645\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.7990 - loss: 0.6530 - val_accuracy: 0.9586 - val_loss: 0.1337\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9393 - loss: 0.2051 - val_accuracy: 0.9664 - val_loss: 0.1105\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9529 - loss: 0.1624 - val_accuracy: 0.9693 - val_loss: 0.0984\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9592 - loss: 0.1354 - val_accuracy: 0.9728 - val_loss: 0.0875\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9638 - loss: 0.1204 - val_accuracy: 0.9751 - val_loss: 0.0801\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9672 - loss: 0.1095 - val_accuracy: 0.9767 - val_loss: 0.0748\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9702 - loss: 0.0953 - val_accuracy: 0.9791 - val_loss: 0.0702\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9696 - loss: 0.0985 - val_accuracy: 0.9784 - val_loss: 0.0666\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 0.0896 - val_accuracy: 0.9789 - val_loss: 0.0660\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9740 - loss: 0.0840 - val_accuracy: 0.9788 - val_loss: 0.0645\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.8056 - loss: 0.6367 - val_accuracy: 0.9532 - val_loss: 0.1484\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9401 - loss: 0.2010 - val_accuracy: 0.9699 - val_loss: 0.0993\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9531 - loss: 0.1568 - val_accuracy: 0.9736 - val_loss: 0.0823\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9602 - loss: 0.1306 - val_accuracy: 0.9773 - val_loss: 0.0754\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.9647 - loss: 0.1191 - val_accuracy: 0.9760 - val_loss: 0.0804\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9681 - loss: 0.1072 - val_accuracy: 0.9763 - val_loss: 0.0767\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9707 - loss: 0.0978 - val_accuracy: 0.9791 - val_loss: 0.0689\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9716 - loss: 0.0926 - val_accuracy: 0.9804 - val_loss: 0.0679\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9747 - loss: 0.0830 - val_accuracy: 0.9799 - val_loss: 0.0653\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9764 - loss: 0.0754 - val_accuracy: 0.9805 - val_loss: 0.0657\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.7943 - loss: 0.6723 - val_accuracy: 0.9600 - val_loss: 0.1355\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9414 - loss: 0.1980 - val_accuracy: 0.9668 - val_loss: 0.1034\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9527 - loss: 0.1572 - val_accuracy: 0.9708 - val_loss: 0.0869\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9603 - loss: 0.1326 - val_accuracy: 0.9714 - val_loss: 0.0875\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9646 - loss: 0.1146 - val_accuracy: 0.9722 - val_loss: 0.0844\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9653 - loss: 0.1109 - val_accuracy: 0.9761 - val_loss: 0.0769\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9700 - loss: 0.0977 - val_accuracy: 0.9783 - val_loss: 0.0701\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.9698 - loss: 0.0955 - val_accuracy: 0.9789 - val_loss: 0.0667\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.9730 - loss: 0.0883 - val_accuracy: 0.9807 - val_loss: 0.0642\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9757 - loss: 0.0846 - val_accuracy: 0.9805 - val_loss: 0.0644\n",
            "Test Accuracies for each run: [0.9810000061988831, 0.9811000227928162, 0.9787999987602234, 0.9804999828338623, 0.9804999828338623]\n",
            "Average Test Accuracy: 0.9803799986839294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is of Feedforward Neural Network which has been run over for 10 epochs and 5 times to get the average accuracy of the network.\n",
        "\n",
        "The average test accuracy comes out to be: 98.03%."
      ],
      "metadata": {
        "id": "id1hdUO-qgPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Function to load MNIST data\n",
        "def load_mnist_images(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        _, num_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
        "        data = np.fromfile(f, dtype=np.uint8).reshape(num_images, rows, cols)\n",
        "        return data\n",
        "\n",
        "def load_mnist_labels(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        _, num_labels = struct.unpack('>II', f.read(8))\n",
        "        data = np.fromfile(f, dtype=np.uint8)\n",
        "        return data\n",
        "\n",
        "# Paths to the MNIST dataset files\n",
        "train_images_file = '/content/train-images.idx3-ubyte'\n",
        "train_labels_file = '/content/train-labels.idx1-ubyte'\n",
        "test_images_file = '/content/t10k-images.idx3-ubyte'\n",
        "test_labels_file = '/content/t10k-labels.idx1-ubyte'\n",
        "\n",
        "# Load data\n",
        "train_images = load_mnist_images(train_images_file).astype('float32') / 255.0\n",
        "test_images = load_mnist_images(test_images_file).astype('float32') / 255.0\n",
        "train_labels = load_mnist_labels(train_labels_file).flatten()\n",
        "test_labels = load_mnist_labels(test_labels_file).flatten()\n",
        "\n",
        "# Reshape data\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels_categorical = to_categorical(train_labels, num_classes=10)\n",
        "test_labels_categorical = to_categorical(test_labels, num_classes=10)\n",
        "\n",
        "# Train and evaluate the CNN model for multiple runs\n",
        "num_runs = 5\n",
        "test_accuracies = []\n",
        "\n",
        "for run in range(num_runs):\n",
        "    # Define the CNN model\n",
        "    model = Sequential([\n",
        "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        train_images, train_labels_categorical,\n",
        "        validation_data=(test_images, test_labels_categorical),\n",
        "        epochs=10, batch_size=64, verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    _, test_accuracy = model.evaluate(test_images, test_labels_categorical, verbose=0)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "# Calculate the average testing accuracy\n",
        "average_test_accuracy = np.mean(test_accuracies)\n",
        "\n",
        "# Print the results\n",
        "print(\"Test Accuracies for each run:\", test_accuracies)\n",
        "print(\"Average Test Accuracy:\", average_test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kg5ERL_Dsew",
        "outputId": "089116a7-2fd4-4a08-816c-9deed6322e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 64ms/step - accuracy: 0.8017 - loss: 0.6066 - val_accuracy: 0.9832 - val_loss: 0.0522\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 64ms/step - accuracy: 0.9659 - loss: 0.1117 - val_accuracy: 0.9864 - val_loss: 0.0389\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 64ms/step - accuracy: 0.9755 - loss: 0.0803 - val_accuracy: 0.9892 - val_loss: 0.0325\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 63ms/step - accuracy: 0.9787 - loss: 0.0682 - val_accuracy: 0.9907 - val_loss: 0.0284\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 62ms/step - accuracy: 0.9822 - loss: 0.0594 - val_accuracy: 0.9905 - val_loss: 0.0288\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 63ms/step - accuracy: 0.9841 - loss: 0.0518 - val_accuracy: 0.9912 - val_loss: 0.0257\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 64ms/step - accuracy: 0.9840 - loss: 0.0508 - val_accuracy: 0.9917 - val_loss: 0.0232\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 63ms/step - accuracy: 0.9864 - loss: 0.0441 - val_accuracy: 0.9923 - val_loss: 0.0228\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 62ms/step - accuracy: 0.9879 - loss: 0.0404 - val_accuracy: 0.9922 - val_loss: 0.0233\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 62ms/step - accuracy: 0.9873 - loss: 0.0407 - val_accuracy: 0.9918 - val_loss: 0.0246\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 63ms/step - accuracy: 0.8122 - loss: 0.5770 - val_accuracy: 0.9812 - val_loss: 0.0570\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 63ms/step - accuracy: 0.9657 - loss: 0.1133 - val_accuracy: 0.9868 - val_loss: 0.0391\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 64ms/step - accuracy: 0.9773 - loss: 0.0778 - val_accuracy: 0.9899 - val_loss: 0.0315\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 62ms/step - accuracy: 0.9797 - loss: 0.0700 - val_accuracy: 0.9902 - val_loss: 0.0307\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 62ms/step - accuracy: 0.9817 - loss: 0.0589 - val_accuracy: 0.9908 - val_loss: 0.0281\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 63ms/step - accuracy: 0.9837 - loss: 0.0549 - val_accuracy: 0.9902 - val_loss: 0.0270\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 64ms/step - accuracy: 0.9851 - loss: 0.0485 - val_accuracy: 0.9919 - val_loss: 0.0243\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 63ms/step - accuracy: 0.9860 - loss: 0.0458 - val_accuracy: 0.9936 - val_loss: 0.0228\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 62ms/step - accuracy: 0.9868 - loss: 0.0424 - val_accuracy: 0.9932 - val_loss: 0.0224\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 62ms/step - accuracy: 0.9885 - loss: 0.0386 - val_accuracy: 0.9924 - val_loss: 0.0233\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 65ms/step - accuracy: 0.8171 - loss: 0.5719 - val_accuracy: 0.9796 - val_loss: 0.0590\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 62ms/step - accuracy: 0.9655 - loss: 0.1128 - val_accuracy: 0.9849 - val_loss: 0.0433\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 65ms/step - accuracy: 0.9758 - loss: 0.0822 - val_accuracy: 0.9867 - val_loss: 0.0384\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 63ms/step - accuracy: 0.9790 - loss: 0.0701 - val_accuracy: 0.9886 - val_loss: 0.0321\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 63ms/step - accuracy: 0.9829 - loss: 0.0573 - val_accuracy: 0.9897 - val_loss: 0.0296\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 65ms/step - accuracy: 0.9833 - loss: 0.0530 - val_accuracy: 0.9895 - val_loss: 0.0298\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 65ms/step - accuracy: 0.9867 - loss: 0.0454 - val_accuracy: 0.9917 - val_loss: 0.0239\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 65ms/step - accuracy: 0.9864 - loss: 0.0421 - val_accuracy: 0.9911 - val_loss: 0.0259\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 63ms/step - accuracy: 0.9884 - loss: 0.0393 - val_accuracy: 0.9923 - val_loss: 0.0212\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 64ms/step - accuracy: 0.9873 - loss: 0.0372 - val_accuracy: 0.9923 - val_loss: 0.0229\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 64ms/step - accuracy: 0.8067 - loss: 0.5948 - val_accuracy: 0.9811 - val_loss: 0.0580\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 63ms/step - accuracy: 0.9668 - loss: 0.1084 - val_accuracy: 0.9869 - val_loss: 0.0394\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 64ms/step - accuracy: 0.9751 - loss: 0.0803 - val_accuracy: 0.9881 - val_loss: 0.0334\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 63ms/step - accuracy: 0.9806 - loss: 0.0644 - val_accuracy: 0.9897 - val_loss: 0.0262\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 63ms/step - accuracy: 0.9823 - loss: 0.0598 - val_accuracy: 0.9902 - val_loss: 0.0277\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 62ms/step - accuracy: 0.9837 - loss: 0.0538 - val_accuracy: 0.9909 - val_loss: 0.0248\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 63ms/step - accuracy: 0.9842 - loss: 0.0512 - val_accuracy: 0.9922 - val_loss: 0.0238\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 62ms/step - accuracy: 0.9868 - loss: 0.0442 - val_accuracy: 0.9920 - val_loss: 0.0255\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 63ms/step - accuracy: 0.9868 - loss: 0.0408 - val_accuracy: 0.9927 - val_loss: 0.0230\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 63ms/step - accuracy: 0.9879 - loss: 0.0392 - val_accuracy: 0.9920 - val_loss: 0.0242\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 63ms/step - accuracy: 0.7941 - loss: 0.6358 - val_accuracy: 0.9816 - val_loss: 0.0605\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 62ms/step - accuracy: 0.9647 - loss: 0.1215 - val_accuracy: 0.9874 - val_loss: 0.0379\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 64ms/step - accuracy: 0.9748 - loss: 0.0850 - val_accuracy: 0.9888 - val_loss: 0.0342\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 62ms/step - accuracy: 0.9784 - loss: 0.0700 - val_accuracy: 0.9912 - val_loss: 0.0264\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 62ms/step - accuracy: 0.9816 - loss: 0.0619 - val_accuracy: 0.9916 - val_loss: 0.0248\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 64ms/step - accuracy: 0.9843 - loss: 0.0535 - val_accuracy: 0.9925 - val_loss: 0.0236\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 64ms/step - accuracy: 0.9852 - loss: 0.0502 - val_accuracy: 0.9917 - val_loss: 0.0230\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 63ms/step - accuracy: 0.9859 - loss: 0.0452 - val_accuracy: 0.9922 - val_loss: 0.0221\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 63ms/step - accuracy: 0.9868 - loss: 0.0425 - val_accuracy: 0.9937 - val_loss: 0.0191\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 64ms/step - accuracy: 0.9885 - loss: 0.0380 - val_accuracy: 0.9927 - val_loss: 0.0223\n",
            "Test Accuracies for each run: [0.9918000102043152, 0.9923999905586243, 0.9922999739646912, 0.9919999837875366, 0.9926999807357788]\n",
            "Average Test Accuracy: 0.9922399878501892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is of Convolutional Neural Network which has been run over for 10 epochs and 5 times to get the average accuracy of the network.\n",
        "\n",
        "The average test accuracy comes out to be: 99.22%."
      ],
      "metadata": {
        "id": "vQBAbBQqq9vW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8xwRhOg3DtqH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}